# ğŸ§  Maze Solving Algorithms Project

This project implements and compares a wide range of algorithms to solve maze navigation problems, using both **traditional search methods** and **modern machine learning approaches**. The maze environment is built with `pyamaze`, and performance is evaluated on a 100Ã—100 grid.

---

## ğŸ“ Project Structure

```text
Maze/
â”œâ”€â”€ algorithms/               # Algorithm implementations
â”‚   â”œâ”€â”€ Astar.py             # A* Search
â”‚   â”œâ”€â”€ BFS.py               # Breadth-First Search
â”‚   â”œâ”€â”€ DFS.py               # Depth-First Search
â”‚   â”œâ”€â”€ IDS.py               # Iterative Deepening Search
â”‚   â”œâ”€â”€ UCS.py               # Uniform Cost Search
â”‚   â”œâ”€â”€ Greedy-search.py     # Greedy Best-First Search
â”‚   â”œâ”€â”€ Hill_Climbing.py     # Hill Climbing
â”‚   â”œâ”€â”€ sim_annealing.py     # Simulated Annealing
â”‚   â”œâ”€â”€ Qlearning.py         # Q-Learning (Reinforcement Learning)
â”‚   â””â”€â”€ genetic_algo.py      # Genetic Algorithm
â”‚
â”œâ”€â”€ core/                    # Core maze and environment logic
â”‚   â”œâ”€â”€ maze.py              # Maze generation and control
â”‚   â””â”€â”€ pyMaze.py            # Maze environment and data structures
â”‚
â”œâ”€â”€ utils/                   # Utilities and tools
â”‚   â”œâ”€â”€ visuals.py           # Visualization utilities
â”‚   â””â”€â”€ performance.py       # Performance measurement and logging
â”‚
â”œâ”€â”€ AI_Report.pdf            # Detailed analysis and algorithm report
â””â”€â”€ README.md                # Project documentation
```

---

## ğŸ” Algorithms Implemented

### ğŸ”¹ Traditional Search

* **BFS** â€” Guarantees shortest path, complete
* **DFS** â€” Fast but not optimal or complete
* **UCS** â€” Optimal with cost, variant of Dijkstraâ€™s
* **IDS** â€” Combines DFS space efficiency and BFS completeness
* **A**\* â€” Uses cost and heuristic (Manhattan distance)

### ğŸ”¹ Heuristic & Local Search

* **Greedy Best-First** â€” Fast but prone to suboptimal paths
* **Hill Climbing** â€” Simple local optimizer
* **Simulated Annealing** â€” Escapes local optima using probabilistic decisions

### ğŸ”¹ Machine Learning

* **Q-Learning** â€” Reinforcement learning with Q-table
* **Genetic Algorithm** â€” Evolutionary method for sequence optimization

---

## ğŸ§  Features

* âœ… Multiple Search and ML Algorithms
* ğŸ“ˆ Real-time Visualization
* ğŸ§ª Performance Metrics and Comparisons
* ğŸ§š Evolutionary & Learning-based Solutions

---

## ğŸ§¹ Problem Setup

* **Grid**: 100Ã—100 maze
* **Start**: Top-left corner `(1, 1)`
* **Goal**: Bottom-right corner `(100, 100)`
* **Actions**: N, S, E, W
* **Constraints**: Transitions blocked by walls

---

## ğŸ’» Usage Examples

### â–¶ï¸ Run BFS (or any other search)

```python
from pyamaze import maze, agent
from BFS import bfs

m = maze()
m.CreateMaze()
path = bfs(m)

a = agent(m, footprints=True)
m.tracePath({a: path})
m.run()
```

### â–¶ï¸ Run Q-Learning

```python
from Qlearning import QLearningMaze
from pyamaze import maze

m = maze(20, 20)
m.CreateMaze()
q_agent = QLearningMaze(m, ['N', 'E', 'W', 'S'])
q_agent.train(episodes=1000)

policy = q_agent.get_policy()
path = q_agent.generate_path((1, 1), m._goal, policy)
```

### â–¶ï¸ Run Genetic Algorithm

```python
from genetic_algo import genetic_algorithm_maze
from pyamaze import maze

m = maze()
m.CreateMaze()
path = genetic_algorithm_maze(m, ['N', 'E', 'S', 'W'], f_thres=0, ngen=500, pmut=0.2)
```

---


## ğŸ“š Report

Full details on algorithm design, evaluation, and results are documented.

---

## ğŸ”§ Requirements

* Python 3.x
* Required packages:

  * `numpy`
  * `random`
  * `time`
  * `pyamaze`

Install with:

```bash
pip install -r requirements.txt
```

---




